#!/usr/bin/python3
# coding: utf-8

import re
import time
from dataclasses import dataclass
from datetime import datetime
from argparse import ArgumentParser
from configparser import ConfigParser
from pprint import pprint
from subprocess import Popen, PIPE, CalledProcessError, run

SNAP_TIME_FORMAT = "snap-%Y-%m-%dT%H:%M:%S"
SNAP_PATTERN = re.compile(r"snap-\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}$")


class PipelineError(Exception):
    pass


@dataclass
class SSHConfig:
    host: str


@dataclass
class RetentionConfig:
    monthly: int
    weekly: int
    daily: int


@dataclass
class Config:
    ssh: SSHConfig
    retention: RetentionConfig
    datasets: dict

    @classmethod
    def parse(cls, raw_config):
        parsed_retention = {
            name: int(value) for name, value in raw_config["retention"].items()
        }
        return Config(
            ssh=SSHConfig(host=raw_config["ssh"]["host"]),
            retention=RetentionConfig(**parsed_retention),
            datasets=raw_config["datasets"],
        )


def snap(dataset, timestamp):
    snapshot_name = f"{dataset}@{timestamp}"
    run(["zfs", "snapshot", snapshot_name], check=True)
    return snapshot_name


def list_snaps(dataset, host=None):
    args = ["zfs", "list", "-t", "snapshot", "-H", "-o", "name", dataset]
    if host:
        args = ["ssh", host] + args
    cmd = run(args, capture_output=True)
    snaps = cmd.stdout.decode().split()
    return [x for x in snaps if SNAP_PATTERN.search(x)]


def send(snapshot, host, target_dataset, base_snaphost=None):
    args = ["zfs", "send"]
    if base_snaphost:
        args += ["-I", base_snaphost]
    args.append(snapshot)

    send_cmd = Popen(args, stdout=PIPE, stderr=PIPE)
    recv_cmd = Popen(
        ["ssh", host, "zfs", "receive", "-vF", target_dataset],
        stdin=send_cmd.stdout,
        stdout=PIPE,
        stderr=PIPE,
    )
    if send_cmd.stdout is not None:
        send_cmd.stdout.close()
    r_stdout, r_stderr = recv_cmd.communicate()
    s_stdout, s_stderr = send_cmd.communicate()
    if send_cmd.returncode != 0 or recv_cmd.returncode != 0:
        raise PipelineError(
            CalledProcessError(send_cmd.returncode, send_cmd.args, s_stdout, s_stderr),
            CalledProcessError(recv_cmd.returncode, recv_cmd.args, r_stdout, r_stderr),
        )

    print(r_stdout.decode(), end="")


def retain_set(snapshots, policy):
    date_map = {
        snap: datetime.strptime(snap.split("@")[1], SNAP_TIME_FORMAT)
        for snap in snapshots
    }
    retain = set()
    retain.update(
        [snap for snap, date in date_map.items() if date.day == 1][-policy.monthly :]
    )
    retain.update(
        [snap for snap, date in date_map.items() if date.weekday() == 0][
            -policy.weekly :
        ]
    )
    # FIXME look into actual dates to prune dailies
    dailies = list(
        {timestamp.date(): snap for snap, timestamp in date_map.items()}.values()
    )
    retain.update(dailies[-policy.daily :])
    return retain


def prune(snapshots, policy, host=None):
    print(f"Current snaps on {host if host else 'localhost'}:")
    pprint(snapshots)
    retain = retain_set(snapshots, policy)
    print("Retain list:")
    pprint(sorted(retain))
    if not retain:
        raise AssertionError("Retain list should not be empty")
    print("Prune list:")
    prune_list = sorted(set(snapshots) - retain)
    pprint(prune_list)
    if prune_list:
        print("Purge Snaps:")
        prune_snaps = prune_list[0:1] + list(
            map(lambda x: x.split("@")[1], prune_list[1:])
        )

        args = ["zfs", "destroy", "-v", ",".join(prune_snaps)]
        if host:
            args = ["ssh", host] + args
        prune_cmd = run(args, capture_output=True, check=True)
        print(prune_cmd.stdout.decode())


def main():
    parser = ArgumentParser(
        prog="ZFS Replication",
        description="Script to automate zfs replication",
    )
    parser.add_argument("-f", dest="config_file", default="config.ini")
    args = parser.parse_args()

    raw_config = ConfigParser()
    raw_config.read(args.config_file)
    config = Config.parse(raw_config)
    timestamp = time.strftime(SNAP_TIME_FORMAT)

    for src_dataset, dst_dataset in config.datasets.items():
        print("##################################################################")
        print(
            "Start replication from",
            src_dataset,
            "to",
            dst_dataset,
            "on",
            config.ssh.host,
        )
        snapshot_name = snap(src_dataset, timestamp)

        remote_snaps = list_snaps(dst_dataset, config.ssh.host)

        if remote_snaps:
            print("Sending incremental stream")
            latest_snap = remote_snaps[-1].split("@")[1]
            send(snapshot_name, config.ssh.host, dst_dataset, base_snaphost=latest_snap)
        else:
            print("No base snaphost found, send full stream")
            send(snapshot_name, config.ssh.host, dst_dataset)

        local_snaps = list_snaps(src_dataset)
        prune(local_snaps, config.retention)
        remote_snaps = list_snaps(dst_dataset, host=config.ssh.host)
        prune(remote_snaps, config.retention, host=config.ssh.host)


if __name__ == "__main__":
    try:
        main()
    except CalledProcessError as e:
        print(e)
        if e.stderr:
            print(e.stderr.decode(), end="")
        exit(e.returncode)
    except PipelineError as pe:
        returncode = 0
        for e in pe.args:
            print(e)
            if e.stderr:
                print(e.stderr.decode(), end="")
            returncode += e.returncode
        exit(returncode)
